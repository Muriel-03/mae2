{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Introducción\n",
    "\n",
    "## Creando el ambiente de trabajo\n",
    "\n",
    "## Con Python\n",
    "\n",
    "Con python instalado en nuestro computador, vamos a crear un ambiente virtual con el siguiente comando:\n",
    "\n",
    "* python -m venv env (Windows/Unix/macOS)\n",
    "\n",
    "Para activar este entorno virtual, se ejecutara el siguiente comando:\n",
    "\n",
    "* .\\env\\Scripts\\activate (Windows)\n",
    "* source env/bin/activate (Unix/macOS)\n",
    "\n",
    "Para desactivar el entorno virtual, ejecute el siguiente comando:\n",
    "\n",
    "* deactivate\n",
    "\n",
    "Mas información sobre los ambientes virtuales nativos de python en el siguiente [link](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#using-requirements-files).\n",
    "\n",
    "## Con Codespaces de Github\n",
    "\n",
    "Para crear un entorno virtual, se ejecutara el siguiente comando:\n",
    "\n",
    "* virtualenv ~/.venv\n",
    "\n",
    "Para activar este entorno virtual, se ejecutara el siguiente comando:\n",
    "\n",
    "* source ~/.venv/bin/activate\n",
    "\n",
    "## Con Anaconda\n",
    "\n",
    "Todos los comandos de conda se deben ejecutar en el terminal en donde tengan instalado Conda. En windows puede ejecutarse en el terminal si es que se agrega el path a las variables de entorno, la instalación por defecto no se agrega y se instala el terminal de anaconda (anaconda prompt). En macOS solo ejecuta en el terminal nativo.\n",
    "\n",
    "Crear un ambiente virtual de anaconda con el siguiente comando:\n",
    "\n",
    "* conda create --name env python=3.8\n",
    "\n",
    "Para activar este entorno virtual, se ejecutara el siguiente comando: \n",
    "\n",
    "* conda activate env \n",
    "\n",
    "Para desactivar este ambiente, se ejecutara el siguiente comando:\n",
    "\n",
    "* conda deactivate\n",
    "\n",
    "Para eliminar el ambiente \n",
    "\n",
    "* conda remove --name env --all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 23:17:29.304561: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-05 23:17:32.026556: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-05 23:17:32.030948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 23:17:37.429006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datasets # Biblioteca de manejo de conjuntos de datos para procesamiento de lenguaje natural\n",
    "import pandas as pd # Biblioteca de manejo de conjuntos de datos\n",
    "import re # Módulo de expresiones regulares\n",
    "from pathlib import Path # Biblioteca para manejo de paths relativos\n",
    "import os # Módulo incorporado en Python que proporciona funciones para interactuar con el sistema operativo\n",
    "import csv # Módulo incorporado en Python que proporciona funciones para leer y escribir archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path relativo\n",
    "data_path=Path('..')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar csv o txt\n",
    "\n",
    "Encoding\n",
    "\n",
    "* UTF-8: 'utf-8' es el encoding predeterminado en Pandas y es ampliamente utilizado para archivos CSV. Es compatible con una amplia gama de caracteres y es recomendado si no estás seguro del encoding del archivo.\n",
    "\n",
    "* Latin-1 (ISO 8859-1): 'latin-1' es otro encoding común utilizado en archivos CSV generados por aplicaciones en entornos Windows. Es compatible con una gran cantidad de idiomas europeos.\n",
    "\n",
    "* UTF-16: 'utf-16' es un encoding de Unicode que utiliza 16 bits para representar los caracteres. Es útil cuando se trabaja con idiomas que tienen una gran cantidad de caracteres, como algunos idiomas asiáticos.\n",
    "\n",
    "* UTF-32: 'utf-32' es un encoding de Unicode que utiliza 32 bits para representar los caracteres. Al igual que UTF-16, es útil para idiomas con una gran cantidad de caracteres.\n",
    "\n",
    "* ASCII: 'ascii' es un encoding básico que solo admite caracteres en inglés y no es compatible con caracteres acentuados u otros caracteres especiales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con el comando `open()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diagnostic', 'is_dental']\n",
      "['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR', '1']\n",
      "['OBTRUCCION FOSA NASAL DERECHA', '0']\n",
      "['Perturbación de la actividad y de la atención Trastorno defícit atencional', '0']\n",
      "['M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 ALGIA PELVICA HTA CRONICA', '0']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "with open(data_path/'spanish_diagnostics/spanish_diagnostics.csv', 'r') as file:\n",
    "  csvreader = csv.reader(file, delimiter=',')\n",
    "  for row in csvreader:\n",
    "    print(row)\n",
    "    i+=1\n",
    "    if i==5:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diagnostic', 'is_dental']\n",
      "['- ANOMALÃ\\x8dAS DENTOFACIALES (INCLUSO LA MALOCLUSIÃ\\x93N)\\n\\n\\n DISCREPANCIA DENTOMAXILAR', '1']\n",
      "['OBTRUCCION FOSA NASAL DERECHA', '0']\n",
      "['PerturbaciÃ³n de la actividad y de la atenciÃ³n Trastorno defÃ\\xadcit atencional', '0']\n",
      "['M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 ALGIA PELVICA HTA CRONICA', '0']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "with open(data_path/'spanish_diagnostics/spanish_diagnostics.csv', 'r',encoding='latin-1') as file:\n",
    "  csvreader = csv.reader(file, delimiter=',')\n",
    "  for row in csvreader:\n",
    "    print(row)\n",
    "    i+=1\n",
    "    if i==5:\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con los dataframes de `Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_diagnostics = pd.read_csv(data_path/'spanish_diagnostics/spanish_diagnostics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>is_dental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OBTRUCCION FOSA NASAL DERECHA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perturbación de la actividad y de la atención ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          diagnostic  is_dental\n",
       "0  - ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUS...          1\n",
       "1                      OBTRUCCION FOSA NASAL DERECHA          0\n",
       "2  Perturbación de la actividad y de la atención ...          0\n",
       "3  M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...          0\n",
       "4  PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_diagnostics_malo = pd.read_csv(data_path/'spanish_diagnostics/spanish_diagnostics.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>is_dental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- ANOMALÃAS DENTOFACIALES (INCLUSO LA MALOCLU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OBTRUCCION FOSA NASAL DERECHA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PerturbaciÃ³n de la actividad y de la atenciÃ³...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          diagnostic  is_dental\n",
       "0  - ANOMALÃAS DENTOFACIALES (INCLUSO LA MALOCLU...          1\n",
       "1                      OBTRUCCION FOSA NASAL DERECHA          0\n",
       "2  PerturbaciÃ³n de la actividad y de la atenciÃ³...          0\n",
       "3  M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...          0\n",
       "4  PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics_malo[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Que pasa si queremos importar muchos archivos txt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion de ejemplo para crear archivos a modo de ejemplo con el dataset anterior. No es importante para este laboratorio.\n",
    "def csv2txt(ruta_csv,ruta_carpeta,cantidad):\n",
    "    i=0\n",
    "    if ruta_carpeta.exists():\n",
    "        pass\n",
    "    else:\n",
    "        ruta_carpeta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(ruta_csv, 'r') as file:\n",
    "        csvreader = csv.reader(file, delimiter=',')\n",
    "        headers=next(csvreader)\n",
    "        for index,row in enumerate(csvreader):\n",
    "            filename = f'archivo_{index}.txt'\n",
    "            with open(ruta_carpeta/filename, 'w') as file_txt:\n",
    "                file_txt.write(row[0])\n",
    "            \n",
    "            i+=1\n",
    "\n",
    "            if i==cantidad:\n",
    "                break\n",
    "            \n",
    "\n",
    "path_csv=data_path/'spanish_diagnostics/spanish_diagnostics.csv'\n",
    "path_carpeta=data_path/'data'/'ejemplo'\n",
    "\n",
    "csv2txt(path_csv,path_carpeta,5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### una manera de leerlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/ejemplo')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archivo_3.txt',\n",
       " 'archivo_4.txt',\n",
       " 'archivo_0.txt',\n",
       " 'archivo_2.txt',\n",
       " 'archivo_1.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos=list(path_carpeta.glob('*.txt')) #que archivos existen en la carpeta\n",
    "archivos_ordenados=sorted(archivos, key=os.path.getmtime) #aca solo se ordena los archivos por fecha de creación\n",
    "[ a.name for a in archivos_ordenados ] #aca solo se presentan los nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 ALGIA PELVICA HTA CRONICA']\n",
      "['PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A CAMARA PULPAR, EVALUAR POR ESPECIALIDAD']\n",
      "['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n', '\\n', '\\n', ' DISCREPANCIA DENTOMAXILAR']\n",
      "['Perturbación de la actividad y de la atención Trastorno defícit atencional']\n",
      "['OBTRUCCION FOSA NASAL DERECHA']\n"
     ]
    }
   ],
   "source": [
    "for archivo in archivos_ordenados:\n",
    "    with open(archivo, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            print(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤗 Datasets\n",
    "\n",
    "🤗 (HuggingFace) Datasets es una biblioteca de manejo de conjuntos de datos para procesamiento de lenguaje natural que se destaca por la simplicidad de sus métodos y el gran repositorio 🤗 Hub que contiene muchos conjuntos de datos libres para descargar sólo con una linea de Python.\n",
    "\n",
    "En nuestro curso trabajaremos con `spanish_diagnostics`, un conjunto de datos de nuestro grupo investigación PLN@CMM que contiene textos de sospechas diagnósticas de la lista de espera chilena y está etiquetado con el destino de la interconsulta; este destino puede ser `dental` o `no_dental`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835851eeb0f844f490710cd6efce1030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset spanish_diagnostics/default to /home/vscode/.cache/huggingface/datasets/fvillena___spanish_diagnostics/default/0.0.0/45c176cea64580ea9631f78c2867a657ede368597681e5337e9f1c976e4e84ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152239f8c0e44ba89e1727631895121a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffbbe987ea141fb86e59bd17aa784d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fd6a5b34a04b2692b26ec317914ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spanish_diagnostics downloaded and prepared to /home/vscode/.cache/huggingface/datasets/fvillena___spanish_diagnostics/default/0.0.0/45c176cea64580ea9631f78c2867a657ede368597681e5337e9f1c976e4e84ff. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ffe3fd581646029f87c42764eff8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spanish_diagnostics = datasets.load_dataset('fvillena/spanish_diagnostics') # Con esta linea descargamos el conjunto de datos completo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro conjunto de datos cuenta con 2 particiones, una partición `train` y otra `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase utilizaremos la partición `train` del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 70000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder facilmente a atributos de nuestro `Dataset`.\n",
    "\n",
    "- `shape`: Tal como en muchas otras bibliotecas de python este atributo contiene la forma de nuestro conjunto de datos con la sintaxis `(filas, columnas)`.\n",
    "- `column_names`: Este atributo contiene el nombre de las características que tiene nuestro conjunto de datos. En nuestro caso tenemos una característica `text`, la cual contiene la hipótesis diagnóstica del conjunto de datos y `label` que contiene el destino al cual fue referido.\n",
    "- `features`: Este atributo nos describe la clase a la que pertenece cada una de las características. En nuestro caso `text` es un `string` y `label` es del tipo `ClassLabel` con 2 clases con nombre `not_dental` y `dental`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_dental', 'dental'], id=None)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"].features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como en muchas otras clases de datos en Python podemos acceder a subconjuntos de datos a través de sus índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       "  'OBTRUCCION FOSA NASAL DERECHA',\n",
       "  'Perturbación de la actividad y de la atención Trastorno defícit atencional'],\n",
       " 'label': [1, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['OBTRUCCION FOSA NASAL DERECHA',\n",
       "  'M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 ALGIA PELVICA HTA CRONICA',\n",
       "  'pieza n 3.4 tratada endodonticamente, restaurada con ionomero y resina compuesta. Necesita protesis fija por gran pNrdida coronaria'],\n",
       " 'label': [0, 0, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"][1,3,5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos acceder a cada una de las características por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       " 'OBTRUCCION FOSA NASAL DERECHA',\n",
       " 'Perturbación de la actividad y de la atención Trastorno defícit atencional']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"]['text'][:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con 🤗 Datasets también podemos trabajar en otras bibliotecas, como por ejemplo importar el conjunto de datos en Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_diagnostics_train_df = pd.DataFrame(spanish_diagnostics[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OBTRUCCION FOSA NASAL DERECHA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perturbación de la actividad y de la atención ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>DM1 Evaluación</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>ABCESO SUBMUCOSO PIEZA 2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>Pbs Inmunodeficiencia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>QUISTE SINOVIAL DEL HUECO POPLITEO, DE BAKER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>MALLET FINGE D 1 MANO DERECHA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      - ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUS...      1\n",
       "1                          OBTRUCCION FOSA NASAL DERECHA      0\n",
       "2      Perturbación de la actividad y de la atención ...      0\n",
       "3      M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 A...      0\n",
       "4      PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A C...      1\n",
       "...                                                  ...    ...\n",
       "69995                                     DM1 Evaluación      1\n",
       "69996                         ABCESO SUBMUCOSO PIEZA 2.6      1\n",
       "69997                              Pbs Inmunodeficiencia      0\n",
       "69998       QUISTE SINOVIAL DEL HUECO POPLITEO, DE BAKER      0\n",
       "69999                      MALLET FINGE D 1 MANO DERECHA      0\n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics_train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que nuestro conjunto de datos tiene sus clases balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    35034\n",
       "0    34966\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics_train_df.label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos localmente un conjunto de datos y queremos importarlo a 🤗 Datasets también podemos hacerlo. Aquí importamos el conjunto de datos desde un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/vscode/.cache/huggingface/datasets/csv/default-c65d9bce3c60ea14/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb3aab3c9d44e60becf831440e482c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7445a7edce9478fb78390da9261b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b38c4b92e974e519cb8f8819eb99e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/vscode/.cache/huggingface/datasets/csv/default-c65d9bce3c60ea14/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4122ae72f77f4fb1b958caa2d109c20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['diagnostic', 'is_dental'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_datos=str(data_path/'spanish_diagnostics/spanish_diagnostics.csv')\n",
    "datasets.load_dataset('csv', data_files=path_datos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "\n",
    "Una de las tareas que podemos realizar sobre las características no estructuradas de texto es la normalización. La cual consiste en llevar nuestro texto a una forma más consistente a lo largo del conjunto de datos.\n",
    "\n",
    "Podemos observar que nuestro conjunto de datos cuenta con una alta inconsistencia respecto al uso de mayúsculas, el uso de tildes y el uso de signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       " 'OBTRUCCION FOSA NASAL DERECHA',\n",
       " 'Perturbación de la actividad y de la atención Trastorno defícit atencional',\n",
       " 'M7 PROLAPSO VAGINAL PARED ANTERIOR G11 G 111 ALGIA PELVICA HTA CRONICA',\n",
       " 'PIEZA 3 CARIES DENTINARIA PROFUNDA PROXIMA A CAMARA PULPAR, EVALUAR POR ESPECIALIDAD',\n",
       " 'pieza n 3.4 tratada endodonticamente, restaurada con ionomero y resina compuesta. Necesita protesis fija por gran pNrdida coronaria',\n",
       " 'PZ. 12 TREPANADA',\n",
       " 'CARCINOMA TORIODEO',\n",
       " 'DISPEPSIA Y METEORISMO',\n",
       " 'ASA 1 DENTICION TEMPORAL MORDIDA CRUZADA']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"][\"text\"][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder llevar todo a minúsculas, simplemente podemos utilizar el método str.lower()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spanish_diagnostics[\"train\"][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- anomalías dentofaciales (incluso la maloclusión)\\n\\n\\n discrepancia dentomaxilar'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence_lower = spanish_diagnostics[\"train\"][\"text\"][0].lower()\n",
    "sample_sentence_lower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expresiones regulares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las expresiones regulares son una herramienta poderosa para manipular y buscar patrones en cadenas de texto. Las expresiones regulares en Python se definen como una secuencia de caracteres que especifican un patrón de búsqueda. Puedes utilizarlas para realizar tareas como validar formatos de cadenas, extraer información específica de un texto o reemplazar partes de una cadena. En python tenemos el paquete re, sus principales funciones son las siguientes:\n",
    "\n",
    "\n",
    "* re.search(pattern, string): Busca el patrón en toda la cadena y devuelve un objeto \"Match\" si encuentra una coincidencia. Puedes utilizar métodos como group() para obtener la cadena que coincide con el patrón.\n",
    "\n",
    "* re.match(pattern, string): Busca el patrón solo al comienzo de la cadena y devuelve un objeto \"Match\" si encuentra una coincidencia.\n",
    "\n",
    "* re.findall(pattern, string): Busca todas las coincidencias del patrón en la cadena y devuelve una lista de cadenas que cumplen con el patrón.\n",
    "\n",
    "* re.sub(pattern, repl, string): Busca todas las coincidencias del patrón en la cadena y las reemplaza con la cadena de reemplazo especificada.\n",
    "\n",
    "Para definir un patrón de expresión regular, puedes utilizar varios caracteres especiales y secuencias de escape. Algunos de los caracteres especiales comunes incluyen:\n",
    "\n",
    "* `.` : Coincide con cualquier carácter excepto una nueva línea.\n",
    "* * Ejemplo: a.b coincide con \"aab\", \"a1b\", \"a@b\", etc., pero no con \"a\\nb\". \n",
    "* `*` : Coincide con cero o más repeticiones del elemento anterior.\n",
    "* * Ejemplo: ab*c coincide con \"ac\", \"abc\", \"abbc\", \"abbbc\", etc.\n",
    "* `+` : Coincide con una o más repeticiones del elemento anterior.\n",
    "* * Ejemplo: ab+c coincide con \"abc\", \"abbc\", \"abbbc\", etc., pero no con \"ac\".\n",
    "* `^` : Coincide con el inicio de una cadena o línea.\n",
    "* * Ejemplo: ^Start coincide con \"Start of line\", pero no con \"End of line: Start\".\n",
    "* `$` : Coincide con el final de una cadena o línea.\n",
    "* * Ejemplo: end$ coincide con \"End of line\", pero no con \"Start of line: End\".\n",
    "* `?` : Coincide con cero o una repetición del elemento anterior.\n",
    "* * Ejemplo: colou?r coincide con \"color\" y \"colour\".\n",
    "* `[ ]`: Coincide con cualquier carácter dentro de los corchetes.\n",
    "* * Ejemplo: `[aeiou]` coincide con cualquier vocal en minúscula.\n",
    "* `( )` : Agrupación de elementos y captura de grupos.\n",
    "* * Ejemplo: (ab)+ coincide con \"ab\", \"abab\", \"ababab\", etc.\n",
    "* `\\` : Se utiliza como carácter de escape para caracteres especiales o para dar significado especial a ciertos caracteres.\n",
    "* * Ejemplo: \\d coincide con cualquier dígito, \\b coincide con una posición en la cadena donde hay un cambio de caracteres de palabra a no palabra o viceversa.\n",
    "* `|` : Coincide con uno de los patrones separados por el operador \"|\".\n",
    "* * Ejemplo: cat|dog coincide con \"cat\" o \"dog\".\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar todo los caracteres no alfabéticos podemos utilizar un patrón de expresión regular con la sintaxis: `[^a-zñáéíóú]`, la cual se explica como:\n",
    "\n",
    "- `[^`: Este es un `NO` lógico que invierte todo lo que viene a su derecha.\n",
    "- `a-z`: Este patrón coincide todos los caracteres de la `a` a la `z` (minúsculas)\n",
    "- `áéíóú`: Este patrón coincide con todas las vocales con tilde.\n",
    "\n",
    "Todos estos patrones están concatenados con un `O` lógico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  anomalías dentofaciales  incluso la maloclusión     discrepancia dentomaxilar'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence_lower_alpha = re.sub(r'[^a-zñáéíóú]', ' ', sample_sentence_lower)\n",
    "sample_sentence_lower_alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos todas las vocales con tilde con con su forma sin tilde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  anomalías dentofaciales  incluso la maloclusion     discrepancia dentomaxilar'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('ó', 'o', sample_sentence_lower_alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos todo en una función que normalizará una cadena de texto que le pasemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text, remove_tildes = True):\n",
    "    \"\"\"Normaliza una cadena de texto convirtiéndo todo a minúsculas, quitando los caracteres no alfabéticos y los tildes\"\"\"\n",
    "    text = text.lower() # Llevamos todo a minúscula\n",
    "    text = re.sub(r'[^A-Za-zñáéíóú]', ' ', text) # Reemplazamos los caracteres no alfabéticos por un espacio\n",
    "    if remove_tildes:\n",
    "        text = re.sub('á', 'a', text) # Reemplazamos los tildes\n",
    "        text = re.sub('é', 'e', text)\n",
    "        text = re.sub('í', 'i', text)\n",
    "        text = re.sub('ó', 'o', text)\n",
    "        text = re.sub('ú', 'u', text)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos del tipo Dataset implementan un método Dataset.map() con el cual podemo aplicar una función a cada una de las instancias de nuesto conjunto de datos. Lo interesante de este método es que aplica la función de manera paralela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052eefc7ba3349ffa4b4026b0f4def56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spanish_diagnostics_normalized = spanish_diagnostics[\"train\"].map(\n",
    "    lambda x: { # Utilizamos una función anónima que devuelve un diccionario\n",
    "        \"normalized_text\" : normalize(x[\"text\"]) # Esta es una nueva característica que agregaremos a nuestro conjunto de datos.\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro conjunto de datos cuenta con una nueva característica `normalized_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       " 'label': 1,\n",
       " 'normalized_text': '  anomalias dentofaciales  incluso la maloclusion     discrepancia dentomaxilar'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['- ANOMALÍAS DENTOFACIALES (INCLUSO LA MALOCLUSIÓN)\\n\\n\\n DISCREPANCIA DENTOMAXILAR',\n",
       "  'OBTRUCCION FOSA NASAL DERECHA',\n",
       "  'Perturbación de la actividad y de la atención Trastorno defícit atencional'],\n",
       " 'label': [1, 0, 0],\n",
       " 'normalized_text': ['  anomalias dentofaciales  incluso la maloclusion     discrepancia dentomaxilar',\n",
       "  'obtruccion fosa nasal derecha',\n",
       "  'perturbacion de la actividad y de la atencion trastorno deficit atencional']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics_normalized[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
