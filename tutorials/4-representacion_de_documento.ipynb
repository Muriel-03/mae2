{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction # Módulo de sklearn para extracción de características\n",
    "import datasets # Biblioteca de manejo de conjuntos de datos para procesamiento de lenguaje natural\n",
    "import numpy as np # Biblioteca de manejo de datos vectoriales\n",
    "import pandas as pd # Biblioteca de manejo de conjuntos de datos\n",
    "import spacy.lang.es # Biblioteca de procesamiento de lenguaje natural\n",
    "import matplotlib.pyplot as plt # Biblioteca de visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos del curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abb62fa2ee946ff8150e735074c9778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset spanish_diagnostics/default to /home/vscode/.cache/huggingface/datasets/fvillena___spanish_diagnostics/default/0.0.0/45c176cea64580ea9631f78c2867a657ede368597681e5337e9f1c976e4e84ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a4e00ceeca40e1a7b1225e22f14cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8c331e27ff431485fc584d126f67f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5e6482bbc54934a5770c1dd450445a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spanish_diagnostics downloaded and prepared to /home/vscode/.cache/huggingface/datasets/fvillena___spanish_diagnostics/default/0.0.0/45c176cea64580ea9631f78c2867a657ede368597681e5337e9f1c976e4e84ff. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32e459aa9d74c02877781bc14248540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spanish_diagnostics = datasets.load_dataset('fvillena/spanish_diagnostics') # Cargamos las particiones de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos una lista de stopwords desde la biblioteca Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.es.stop_words.STOP_WORDS # La biblioteca Spacy tiene una lista de stopwords en español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de documentos\n",
    "\n",
    "Para poder trabajar con datos de texto, estos deben ser representados de una manera que pueda ser interpretada por los algoritmos de minería de texto. Típicamente se desea llegar a una matriz que tenga tantas filas como documentos tenga nuestro corpus y tantas columnas como características fueron extraídas desde el texto.\n",
    "\n",
    "Revisaremos 2 métodos de extracción de características:\n",
    "\n",
    "* Bag-of-words: Este método extrae la frecuencia de aparición de cada una de las palabras del documento y representa un documento como un vector de tantas dimensiones como palabras tenga el vocabulario.\n",
    "\n",
    "* Term frequency - inverse document frequency (TF-IDF): Este método extrae la frecuencia de aparición de cada una de las palabras y la multiplica por el inverso de la frecuencia de aparición de la palabra en todos los documentos. También se representa cada documento como un vector de tantas dimensiones como palabras tenga el vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos un extractor de características Bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(\n",
    "    stop_words = list(stopwords), # Le pasamos la lista de stopwords para eliminarlas del vocabulario\n",
    "    max_df = 0.05, # Eliminamos del vocabulario el 5% de palabras más frecuentes (stopwords específicas del corpus)\n",
    "    min_df = 2 # Eliminamos del vocabulario las palabras que tienen una frecuencia menor a 2 (típicamente palabras malformadas)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el vectorizador sobre los textos del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=[&#x27;dar&#x27;, &#x27;siempre&#x27;, &#x27;pocas&#x27;, &#x27;dicen&#x27;, &#x27;más&#x27;, &#x27;una&#x27;,\n",
       "                            &#x27;ante&#x27;, &#x27;al&#x27;, &#x27;ciertas&#x27;, &#x27;días&#x27;, &#x27;habrá&#x27;, &#x27;algunas&#x27;,\n",
       "                            &#x27;según&#x27;, &#x27;primero&#x27;, &#x27;primer&#x27;, &#x27;diferente&#x27;, &#x27;soy&#x27;,\n",
       "                            &#x27;qeu&#x27;, &#x27;será&#x27;, &#x27;siguiente&#x27;, &#x27;tiene&#x27;, &#x27;poner&#x27;,\n",
       "                            &#x27;otro&#x27;, &#x27;aquello&#x27;, &#x27;haciendo&#x27;, &#x27;quizás&#x27;, &#x27;indicó&#x27;,\n",
       "                            &#x27;debido&#x27;, &#x27;esos&#x27;, &#x27;próximos&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=[&#x27;dar&#x27;, &#x27;siempre&#x27;, &#x27;pocas&#x27;, &#x27;dicen&#x27;, &#x27;más&#x27;, &#x27;una&#x27;,\n",
       "                            &#x27;ante&#x27;, &#x27;al&#x27;, &#x27;ciertas&#x27;, &#x27;días&#x27;, &#x27;habrá&#x27;, &#x27;algunas&#x27;,\n",
       "                            &#x27;según&#x27;, &#x27;primero&#x27;, &#x27;primer&#x27;, &#x27;diferente&#x27;, &#x27;soy&#x27;,\n",
       "                            &#x27;qeu&#x27;, &#x27;será&#x27;, &#x27;siguiente&#x27;, &#x27;tiene&#x27;, &#x27;poner&#x27;,\n",
       "                            &#x27;otro&#x27;, &#x27;aquello&#x27;, &#x27;haciendo&#x27;, &#x27;quizás&#x27;, &#x27;indicó&#x27;,\n",
       "                            &#x27;debido&#x27;, &#x27;esos&#x27;, &#x27;próximos&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=['dar', 'siempre', 'pocas', 'dicen', 'más', 'una',\n",
       "                            'ante', 'al', 'ciertas', 'días', 'habrá', 'algunas',\n",
       "                            'según', 'primero', 'primer', 'diferente', 'soy',\n",
       "                            'qeu', 'será', 'siguiente', 'tiene', 'poner',\n",
       "                            'otro', 'aquello', 'haciendo', 'quizás', 'indicó',\n",
       "                            'debido', 'esos', 'próximos', ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(spanish_diagnostics[\"train\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploraremos cómo está representando nuestros documentos este vectorizador.\n",
    "\n",
    "Este es un texto de ejemplo del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- CARIES DENTINARIA PROFUNDA/  - Fundamento Clínico APS: caries profunda en relacion de la pieza dental 4.5 Caries de la dentina'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_diagnostics[\"train\"][\"text\"][69983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_scores(text,vectorizer):\n",
    "    \"\"\"A partir de un texto y un vectorizador retorna los puntajes asignados a cada palabra del texto\"\"\"\n",
    "    feature_names = list({k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}.keys()) # Vocabulario\n",
    "    doc = vectorizer.transform([text]) # Vectorizamos el texto de entrada\n",
    "    idxs = np.argwhere(doc)[:,1] # Extraemos los índices donde sí hay palabras representadas\n",
    "    words = [feature_names[i] for i in idxs] # Extraemos las palabras asociadas a los índices extraídos\n",
    "    scores = np.array(doc.todense())[0][idxs] # Extraemos los puntajes asociadas a los índices extraídos\n",
    "    return list(reversed(sorted(zip(words,scores),key=lambda tup: tup[1]))) # Retornamos una lista de palabras y puntajes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que nuestro vectorizador le dio más peso a la palabra caries de nuestro documento porque es la palabra más frecuente y a a un grupo de palabras les asignó el mismo puntaje 1 porque cada una aprece 1 vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caries', 3),\n",
       " ('profunda', 2),\n",
       " ('relacion', 1),\n",
       " ('fundamento', 1),\n",
       " ('dentinaria', 1),\n",
       " ('dentina', 1),\n",
       " ('dental', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_scores(spanish_diagnostics[\"train\"][\"text\"][69983],count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos un vectorizador que utiliza TF-IDF y lo ajustamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=[&#x27;dar&#x27;, &#x27;siempre&#x27;, &#x27;pocas&#x27;, &#x27;dicen&#x27;, &#x27;más&#x27;, &#x27;una&#x27;,\n",
       "                            &#x27;ante&#x27;, &#x27;al&#x27;, &#x27;ciertas&#x27;, &#x27;días&#x27;, &#x27;habrá&#x27;, &#x27;algunas&#x27;,\n",
       "                            &#x27;según&#x27;, &#x27;primero&#x27;, &#x27;primer&#x27;, &#x27;diferente&#x27;, &#x27;soy&#x27;,\n",
       "                            &#x27;qeu&#x27;, &#x27;será&#x27;, &#x27;siguiente&#x27;, &#x27;tiene&#x27;, &#x27;poner&#x27;,\n",
       "                            &#x27;otro&#x27;, &#x27;aquello&#x27;, &#x27;haciendo&#x27;, &#x27;quizás&#x27;, &#x27;indicó&#x27;,\n",
       "                            &#x27;debido&#x27;, &#x27;esos&#x27;, &#x27;próximos&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=[&#x27;dar&#x27;, &#x27;siempre&#x27;, &#x27;pocas&#x27;, &#x27;dicen&#x27;, &#x27;más&#x27;, &#x27;una&#x27;,\n",
       "                            &#x27;ante&#x27;, &#x27;al&#x27;, &#x27;ciertas&#x27;, &#x27;días&#x27;, &#x27;habrá&#x27;, &#x27;algunas&#x27;,\n",
       "                            &#x27;según&#x27;, &#x27;primero&#x27;, &#x27;primer&#x27;, &#x27;diferente&#x27;, &#x27;soy&#x27;,\n",
       "                            &#x27;qeu&#x27;, &#x27;será&#x27;, &#x27;siguiente&#x27;, &#x27;tiene&#x27;, &#x27;poner&#x27;,\n",
       "                            &#x27;otro&#x27;, &#x27;aquello&#x27;, &#x27;haciendo&#x27;, &#x27;quizás&#x27;, &#x27;indicó&#x27;,\n",
       "                            &#x27;debido&#x27;, &#x27;esos&#x27;, &#x27;próximos&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.05, min_df=2,\n",
       "                stop_words=['dar', 'siempre', 'pocas', 'dicen', 'más', 'una',\n",
       "                            'ante', 'al', 'ciertas', 'días', 'habrá', 'algunas',\n",
       "                            'según', 'primero', 'primer', 'diferente', 'soy',\n",
       "                            'qeu', 'será', 'siguiente', 'tiene', 'poner',\n",
       "                            'otro', 'aquello', 'haciendo', 'quizás', 'indicó',\n",
       "                            'debido', 'esos', 'próximos', ...])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words = list(stopwords),\n",
    "    max_df = 0.05,\n",
    "    min_df = 2\n",
    ")\n",
    "tfidf_vectorizer.fit(spanish_diagnostics[\"train\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que caries sigue siendo la palabra con el mayor puntaje. Pero vemos que todas las palabras tienen un puntaje distinto, en donde destacamos que la palabra fundamento tiene el menor puntaje. Intuitivamente podemos darnos cuenta que esta representación es mejor porque la palabra fundamento no nos aporta mucha información en el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caries', 0.5841232685802328),\n",
       " ('profunda', 0.5052614123771014),\n",
       " ('dentina', 0.36362077674894117),\n",
       " ('relacion', 0.30054370920913476),\n",
       " ('dentinaria', 0.27911008594273823),\n",
       " ('dental', 0.25831112531154554),\n",
       " ('fundamento', 0.19062330472026245)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_scores(spanish_diagnostics[\"train\"][\"text\"][69983],tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizamos los textos de nuestros conjuntos de entrenamiento y prueba. con el método CountVectorizer.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorized_train = count_vectorizer.transform(spanish_diagnostics[\"train\"][\"text\"])\n",
    "text_vectorized_test = count_vectorizer.transform(spanish_diagnostics[\"test\"][\"text\"])\n",
    "feature_names = list({k: v for k, v in sorted(count_vectorizer.vocabulary_.items(), key=lambda item: item[1])}.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de nuestra matriz es de (cantidad de documentos en el conjunto, tamaño del vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 13565)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorized_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13565)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorized_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
